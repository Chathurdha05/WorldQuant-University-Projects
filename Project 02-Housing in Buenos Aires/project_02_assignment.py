# -*- coding: utf-8 -*-
"""Project 02-Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TOr_oqGB1j3I8LnnRYB4OBmBPQKqHP4h

# **2.5. Predicting Apartment Prices in Mexico City ðŸ‡²ðŸ‡½**
"""

import warnings

import wqet_grader

warnings.simplefilter(action="ignore", category=FutureWarning)
wqet_grader.init("Project 2 Assessment")

"""In this assignment, you'll decide which libraries you need to complete the tasks. You can import them in the cell below. ðŸ‘‡"""

# Import libraries here
import warnings
from glob import glob

import pandas as pd
import seaborn as sns
import wqet_grader
from category_encoders import OneHotEncoder
from IPython.display import VimeoVideo
from ipywidgets import Dropdown, FloatSlider, IntSlider, interact
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Ridge  # noqa F401
from sklearn.metrics import mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.utils.validation import check_is_fitted

import matplotlib.pyplot as plt

"""## **Prepare Data**

### **Import**

**Task 2.5.1:** Write a wrangle function that takes the name of a CSV file as input and returns a DataFrame. The function should do the following steps:

1. Subset the data in the CSV file and return only apartments in Mexico City ("Distrito Federal") that cost less than $100,000.
2. Remove outliers by trimming the bottom and top 10% of properties in terms of "surface_covered_in_m2".
3. Create separate "lat" and "lon" columns.
4. Mexico City is divided into 15 boroughs. Create a "borough" feature from the "place_with_parent_names" column.
5. Drop columns that are more than 50% null values.
6. Drop columns containing low- or high-cardinality categorical values.
7. Drop any columns that would constitute leakage for the target "price_aprox_usd".
8. Drop any columns that would create issues of multicollinearity.

**Tip:** Don't try to satisfy all the criteria in the first version of your wrangle function. Instead, work iteratively. Start with the first criteria, test it out with one of the Mexico CSV files in the data/ directory, and submit it to the grader for feedback. Then add the next criteria.
"""

def wrangle(filepath):
    df = pd.read_csv(filepath)
    mask1 = (df['property_type'] == 'apartment')
    mask2 = (df['price_aprox_usd'] < 100000)
    mask3 = (df['place_with_parent_names'].str.contains('Distrito Federal'))


    df = df[mask1 & mask2 & mask3]

    low, high = df['surface_covered_in_m2'].quantile([0.1, 0.9])
    maskArea = df['surface_covered_in_m2'].between(low, high)
    df = df[maskArea]

    df[['lat', 'lon']] = df['lat-lon'].str.split(',', expand=True).astype(float)
    df = df.drop(columns='lat-lon')

    df['borough'] = df['place_with_parent_names'].str.split('|', expand=True)[1]
    df = df.drop(columns='place_with_parent_names')

    columns_na = [i for i in df.columns if df[i].isna().sum() > len(df) // 2]
    df = df.drop(columns = columns_na)

    list_card = ["operation", "property_type",  "currency", "properati_url"]
    df = df.drop(columns = list_card)

    #leakage
    highlow_cardinality = ['price', 'price_aprox_local_currency', 'price_per_m2']
    df = df.drop(columns = highlow_cardinality)



    return df

# Use this cell to test your wrangle function and explore the data
frame = []
for i in files:
    df = wrangle(i)
    frame.append(df)

df = pd.concat(frame)
df.info()

wqet_grader.grade(
    "Project 2 Assessment", "Task 2.5.1", wrangle("data/mexico-city-real-estate-1.csv")
)

"""**Task 2.5.2:** Use glob to create the list files. It should contain the filenames of all the Mexico City real estate CSVs in the ./data directory, except for mexico-city-test-features.csv."""

files = glob("data/mexico-city-real-estate-*.csv")
files

wqet_grader.grade("Project 2 Assessment", "Task 2.5.2", files)

"""**Task 2.5.3:** Combine your wrangle function, a list comprehension, and pd.concat to create a DataFrame df. It should contain all the properties from the five CSVs in files."""

frames = [wrangle(file) for file in files]
df = pd.concat(frames, ignore_index=True)
print(df.info())
df.head()

wqet_grader.grade("Project 2 Assessment", "Task 2.5.3", df)

"""### **Explore**

**Task 2.5.4:** Create a histogram showing the distribution of apartment prices ("price_aprox_usd") in df. Be sure to label the x-axis "Price [$]", the y-axis "Count", and give it the title "Distribution of Apartment Prices". Use Matplotlib (plt).

What does the distribution of price look like? Is the data normal, a little skewed, or very skewed?
"""

import matplotlib.pyplot as plt

# Assuming 'df' is the concatenated DataFrame from the wrangled data
# Build histogram
plt.hist(df["price_aprox_usd"])

# Label axes
plt.xlabel("Price [$]")
plt.ylabel("Count")

# Add title
plt.title("Distribution of Apartment Prices")

# Save the plot as an image
plt.savefig("images/2-5-4.png", dpi=150)

# Show the plot
plt.show()

with open("images/2-5-4.png", "rb") as file:
    wqet_grader.grade("Project 2 Assessment", "Task 2.5.4", file)

"""**Task 2.5.5:** Create a scatter plot that shows apartment price ("price_aprox_usd") as a function of apartment size ("surface_covered_in_m2"). Be sure to label your x-axis "Area [sq meters]" and y-axis "Price [USD]". Your plot should have the title "Mexico City: Price vs. Area". Use Matplotlib (plt)."""

import matplotlib.pyplot as plt

# Build scatter plot with adjusted point size and color
plt.scatter(x=df["surface_covered_in_m2"], y=df["price_aprox_usd"])

# Label axes
plt.xlabel("Area [sq meters]")
plt.ylabel("Price [USD]")

# Add title
plt.title("Mexico City: Price vs. Area");

# Don't delete the code below ðŸ‘‡
plt.savefig("images/2-5-5.png", dpi=150)

"""Do you see a relationship between price and area in the data? How is this similar to or different from the Buenos Aires dataset?"""

with open("images/2-5-5.png", "rb") as file:
    wqet_grader.grade("Project 2 Assessment", "Task 2.5.5", file)

"""**Task 2.5.6:** (UNGRADED) Create a Mapbox scatter plot that shows the location of the apartments in your dataset and represent their price using color.

What areas of the city seem to have higher real estate prices?
"""

import plotly.express as px
# Plot Mapbox location and price
fig = px.scatter_mapbox(
    df,  # Our DataFrame
    lat="lat",
    lon="lon",
    width=600,  # Width of map
    height=600,  # Height of map
    color="price_aprox_usd",
    hover_data=["price_aprox_usd"],  # Display price when hovering
)

# Set map style
fig.update_layout(mapbox_style="open-street-map")

# Show the plot
fig.show()

"""### **Split**

**Task 2.5.7:** Create your feature matrix X_train and target vector y_train. Your target is "price_aprox_usd". Your features should be all the columns that remain in the DataFrame you cleaned above.
"""

df.columns
feature = 'price_aprox_usd'
X_train = df[['surface_covered_in_m2', 'lat', 'lon', 'borough']]
y_train = df[feature]

wqet_grader.grade("Project 2 Assessment", "Task 2.5.7a", X_train)

wqet_grader.grade("Project 2 Assessment", "Task 2.5.7b", y_train)

"""## **Build Model**

### **Baseline**

**Task 2.5.8:** Calculate the baseline mean absolute error for your model.
"""

y_mean = y_train.mean()
y_pred_baseline = [y_mean] *len(y_train)
baseline_mae = mean_absolute_error(y_train, y_pred_baseline)
print("Mean apt price:", y_mean)
print("Baseline MAE:", baseline_mae)

wqet_grader.grade("Project 2 Assessment", "Task 2.5.8", [baseline_mae])

"""### **Iterate**

**Task 2.5.9:** Create a pipeline named model that contains all the transformers necessary for this dataset and one of the predictors you've used during this project. Then fit your model to the training data.
"""

model = make_pipeline(
    OneHotEncoder(use_cat_names = True),
    SimpleImputer(),
    Ridge()
)
model.fit(X_train, y_train)

wqet_grader.grade("Project 2 Assessment", "Task 2.5.9", model)

"""### **Evaluate**

**Task 2.5.10:** Read the CSV file mexico-city-test-features.csv into the DataFrame X_test.

**Tip:** Make sure the X_train you used to train your model has the same column order as X_test. Otherwise, it may hurt your model's performance.
"""

X_test = pd.read_csv('data/mexico-city-test-features.csv')
print(X_test.info())
X_test.head()

wqet_grader.grade("Project 2 Assessment", "Task 2.5.10", X_test)

"""**Task 2.5.11:** Use your model to generate a Series of predictions for X_test. When you submit your predictions to the grader, it will calculate the mean absolute error for your model."""

y_test_pred = model.predict(X_test)
y_test_pred = pd.Series(y_test_pred)
y_test_pred.head()

wqet_grader.grade("Project 2 Assessment", "Task 2.5.11", y_test_pred)

"""## **Communicate Results**

**Task 2.5.12:** Create a Series named feat_imp. The index should contain the names of all the features your model considers when making predictions; the values should be the coefficient values associated with each feature. The Series should be sorted ascending by absolute value.
"""

coefficients = model.named_steps['ridge'].coef_

model.named_steps['ridge'].get_params

coefficients = model.named_steps['ridge'].coef_
features = df.columns
feat_imp = pd.Series(coefficients[:5], index=features)
feat_imp

wqet_grader.grade("Project 2 Assessment", "Task 2.5.12", feat_imp)

"""**Task 2.5.13:** Create a horizontal bar chart that shows the **10 most influential** coefficients for your model. Be sure to label your x- and y-axis "Importance [USD]" and "Feature", respectively, and give your chart the title "Feature Importances for Apartment Price". Use pandas."""

# Build bar chart
feat_imp = feat_imp.head(10)

# Build the horizontal bar chart
feat_imp.plot(kind='barh', color='skyblue')

# Label axes
plt.xlabel('Importance [USD]')
plt.ylabel('Feature')


# Add title
plt.title('Feature Importances for Apartment Price')


# Don't delete the code below ðŸ‘‡
plt.savefig("images/2-5-13.png", dpi=150)

with open("images/2-5-13.png", "rb") as file:
    wqet_grader.grade("Project 2 Assessment", "Task 2.5.13", file)

"""Copyright 2024 WorldQuant University. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited."""