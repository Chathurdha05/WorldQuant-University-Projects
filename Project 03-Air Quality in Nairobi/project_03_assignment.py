# -*- coding: utf-8 -*-
"""Project 03-Assignment.ipynb

Automatically generated by Colab.



# **3.5. Air Quality in Dar es Salaam ðŸ‡¹ðŸ‡¿**
"""

import warnings

import wqet_grader

warnings.simplefilter(action="ignore", category=FutureWarning)
wqet_grader.init("Project 3 Assessment")

# Import libraries here
import inspect
import time
import warnings

import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import seaborn as sns
from IPython.display import VimeoVideo
from pymongo import MongoClient
from sklearn.metrics import mean_absolute_error
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA

warnings.filterwarnings("ignore")

"""## **Prepare Data**

### **Connect**

**Task 3.5.1:** Connect to MongoDB server running at host "localhost" on port 27017. Then connect to the "air-quality" database and assign the collection for Dar es Salaam to the variable name dar.
"""

from pymongo import MongoClient

client = MongoClient(host="localhost", port=27017)
db = client["air-quality"]
dar = db["dar-es-salaam"]

wqet_grader.grade("Project 3 Assessment", "Task 3.5.1", [dar.name])

"""### **Explore**

**Task 3.5.2:** Determine the numbers assigned to all the sensor sites in the Dar es Salaam collection. Your submission should be a list of integers.
"""

sites = sorted(dar.distinct("metadata.site"))
sites

wqet_grader.grade("Project 3 Assessment", "Task 3.5.2", sites)

"""**Task 3.5.3:** Determine which site in the Dar es Salaam collection has the most sensor readings (of any type, not just PM2.5 readings). You submission readings_per_site should be a list of dictionaries that follows this format:

[{'_id': 6, 'count': 70360}, {'_id': 29, 'count': 131852}]

Note that the values here â˜ï¸ are from the Nairobi collection, so your values will look different.
"""

readings_per_site = list(dar.aggregate([
    {"$group": {"_id": "$metadata.site", "count": {"$sum": 1}}},
    {"$sort": {"count": -1}}
]))
readings_per_site

wqet_grader.grade("Project 3 Assessment", "Task 3.5.3", readings_per_site)

"""### **Import**

**Task 3.5.4:** Create a wrangle function that will extract the PM2.5 readings from the site that has the most total readings in the Dar es Salaam collection. Your function should do the following steps:

1. Localize reading time stamps to the timezone for "Africa/Dar_es_Salaam".
2. Remove all outlier PM2.5 readings that are above 100.
3. Resample the data to provide the mean PM2.5 reading for each hour.
4. Impute any missing values using the forward-fill method.
5. Return a Series y.
"""

def wrangle(dar):
    import pandas as pd

    # Step 1: Find the site with the most P2 readings (PM2.5)
    pipeline = [
        {"$match": {"metadata.measurement": "P2"}},
        {"$group": {"_id": "$metadata.site", "count": {"$sum": 1}}},
        {"$sort": {"count": -1}},
        {"$limit": 1}
    ]
    agg_result = list(dar.aggregate(pipeline))
    if not agg_result:
        raise ValueError("No P2 readings found in the collection.")
    most_readings_site = agg_result[0]['_id']

    # Step 2: Get P2 readings from that site
    cursor = dar.find(
        {"metadata.site": most_readings_site, "metadata.measurement": "P2"},
        {"_id": 0, "timestamp": 1, "P2": 1}
    )
    docs = list(cursor)
    if not docs:
        raise ValueError("No P2 documents found for the selected site.")

    # Step 3: Load into DataFrame
    df = pd.DataFrame(docs)

    # Step 4: Parse datetime and localize
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df = df.set_index("timestamp").sort_index()
    df.index = df.index.tz_localize("UTC").tz_convert("Africa/Dar_es_Salaam")

    # Step 5: Remove outliers (PM2.5 > 100)
    df = df[df["P2"] <= 100]

    # Step 6: Resample to hourly mean and forward-fill
    y = df["P2"].resample("1H").mean().ffill()

    return y

"""Use your wrangle function to query the dar collection and return your cleaned results."""

# Run the wrangle function to get cleaned data
y = wrangle(dar)

# Display the first few rows of the cleaned data
y.head()

wqet_grader.grade("Project 3 Assessment", "Task 3.5.4", wrangle(dar))

"""### **Explore Some More**

**Task 3.5.5:** Create a time series plot of the readings in y. Label your x-axis "Date" and your y-axis "PM2.5 Level". Use the title "Dar es Salaam PM2.5 Levels".
"""

fig, ax = plt.subplots(figsize=(15, 6))
y.plot(ax=ax)

# Set title and labels
ax.set_title("Dar es Salaam PM2.5 Levels")
ax.set_xlabel("Date")
ax.set_ylabel("PM2.5 Level")

# Don't delete the code below ðŸ‘‡
plt.savefig("images/3-5-5.png", dpi=150)

with open("images/3-5-5.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.5", file)

"""**Task 3.5.6:** Plot the rolling average of the readings in y. Use a window size of 168 (the number of hours in a week). Label your x-axis "Date" and your y-axis "PM2.5 Level". Use the title "Dar es Salaam PM2.5 Levels, 7-Day Rolling Average"."""

rolling_avg = y.rolling(window=168).mean()
fig, ax = plt.subplots(figsize=(15, 6))
ax.plot(rolling_avg, label="7-Day Rolling Average", color="blue")
ax.set_xlabel("Date")
ax.set_ylabel("PM2.5 Level")
ax.set_title("Dar es Salaam PM2.5 Levels, 7-Day Rolling Average")
ax.legend()

# Don't delete the code below ðŸ‘‡
plt.savefig("images/3-5-6.png", dpi=150)

with open("images/3-5-6.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.6", file)

"""**Task 3.5.7:** Create an ACF plot for the data in y. Be sure to label the x-axis as "Lag [hours]" and the y-axis as "Correlation Coefficient". Use the title "Dar es Salaam PM2.5 Readings, ACF"."""

fig, ax = plt.subplots(figsize=(15, 6))
plot_acf(y, lags=100, ax=ax)

# Set labels and title
ax.set_xlabel("Lag [hours]")
ax.set_ylabel("Correlation Coefficient")
ax.set_title("Dar es Salaam PM2.5 Readings, ACF")

# Don't delete the code below ðŸ‘‡
plt.savefig("images/3-5-7.png", dpi=150)

with open("images/3-5-7.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.7", file)

"""**Task 3.5.8:** Create an PACF plot for the data in y. Be sure to label the x-axis as "Lag [hours]" and the y-axis as "Correlation Coefficient". Use the title "Dar es Salaam PM2.5 Readings, PACF"."""

fig, ax = plt.subplots(figsize=(15, 6))
plot_pacf(y, lags=100, ax=ax, method="ywm")

# Set labels and title
ax.set_xlabel("Lag [hours]")
ax.set_ylabel("Correlation Coefficient")
ax.set_title("Dar es Salaam PM2.5 Readings, PACF")

# Don't delete the code below ðŸ‘‡
plt.savefig("images/3-5-8.png", dpi=150)

with open("images/3-5-8.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.8", file)

"""### **Split**

**Task 3.5.9:** Split y into training and test sets. The first 90% of the data should be in your training set. The remaining 10% should be in the test set.
"""

cutoff_test = int(len(y) * 0.9)

y_train = y.iloc[:cutoff_test]
y_test = y.iloc[cutoff_test:]
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

wqet_grader.grade("Project 3 Assessment", "Task 3.5.9a", y_train)

wqet_grader.grade("Project 3 Assessment", "Task 3.5.9b", y_test)

"""## **Build Model**

### **Baseline**

**Task 3.5.10:** Establish the baseline mean absolute error for your model.
"""

y_train_mean = y_train.mean()
y_pred_baseline = [y_train_mean] * len(y_train)
mae_baseline = mean_absolute_error(y_train, y_pred_baseline)

print("Mean P2 Reading:", round(y_train_mean, 2))
print("Baseline MAE:", round(mae_baseline, 2))

wqet_grader.grade("Project 3 Assessment", "Task 3.5.10", mae_baseline)

"""### **Iterate**

**Task 3.5.11:** You're going to use an AutoReg model to predict PM2.5 readings, but which hyperparameter settings will give you the best performance? Use a for loop to train your AR model on using settings for lags from 1 to 30. Each time you train a new model, calculate its mean absolute error and append the result to the list maes. Then store your results in the Series mae_series.

**Tip:** In this task, you'll need to combine the model you learned about in Task 3.3.8 with the hyperparameter tuning technique you learned in Task 3.4.9.
"""

from statsmodels.tsa.ar_model import AutoReg

# Create range to test different lags
p_params = range(1, 31)

# Create empty list to hold mean absolute error scores
maes = []

# Iterate through all values of p in `p_params`
for p in p_params:
    # Build model
    model = AutoReg(y_train, lags=p).fit()

    # Make predictions on training data, dropping null values caused by lag
    y_pred = model.predict().dropna()

    # Calculate mean absolute error for training data vs predictions
    mae = mean_absolute_error(y_train.iloc[p:], y_pred)

    # Append `mae` to list `maes`
    maes.append(mae)

# Put list `maes` into Series with index `p_params`
mae_series = pd.Series(maes, name="mae", index=p_params)

# Inspect head of Series
mae_series.head()

wqet_grader.grade("Project 3 Assessment", "Task 3.5.11", mae_series)

"""**Task 3.5.12:** Look through the results in mae_series and determine what value for p provides the best performance. Then build and train best_model using the best hyperparameter value.

**Note:** Make sure that you build and train your model in one line of code, and that the data type of best_model is statsmodels.tsa.ar_model.AutoRegResultsWrapper.
"""

best_p = mae_series.idxmin()
best_model = AutoReg(y_train, lags=best_p).fit()

wqet_grader.grade(
    "Project 3 Assessment", "Task 3.5.12", [isinstance(best_model.model, AutoReg)]
)

"""**Task 3.5.13:** Calculate the training residuals for best_model and assign the result to y_train_resid. **Note** that your name of your Series should be "residuals"."""

y_train_resid = y_train - best_model.fittedvalues
y_train_resid.name = "residuals"
y_train_resid.head()

wqet_grader.grade("Project 3 Assessment", "Task 3.5.13", y_train_resid.tail(1500))

"""**Task 3.5.14:** Create a histogram of y_train_resid. Be sure to label the x-axis as "Residuals" and the y-axis as "Frequency". Use the title "Best Model, Training Residuals"."""

# Plot histogram of residuals

# Don't delete the code below ðŸ‘‡
plt.savefig("images/3-5-14.png", dpi=150)

with open("images/3-5-14.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.14", file)

"""**Task 3.5.15:** Create an ACF plot for y_train_resid. Be sure to label the x-axis as "Lag [hours]" and y-axis as "Correlation Coefficient". Use the title "Dar es Salaam, Training Residuals ACF"."""

from statsmodels.graphics.tsaplots import plot_acf

# Plot ACF of residuals
fig, ax = plt.subplots(figsize=(15, 6))
plot_acf(y_train_resid, ax=ax)

# Set labels and title
ax.set_xlabel("Lag [hours]")
ax.set_ylabel("Correlation Coefficient")
ax.set_title("Dar es Salaam, Training Residuals ACF")

# Save the figure
plt.savefig("images/3-5-15.png", dpi=150)

with open("images/3-5-15.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.15", file)

"""### **Evaluate**

**Task 3.5.16:** Perform walk-forward validation for your model for the entire test set y_test. Store your model's predictions in the Series y_pred_wfv. Make sure the name of your Series is "prediction" and the name of your Series index is "timestamp".
"""

y_pred_wfv = pd.Series()
history = y_train.copy()
for _ in range(len(y_test)):
    model = AutoReg(history, lags=26).fit()
    next_pred = model.forecast()
    y_pred_wfv = y_pred_wfv.append(next_pred)
    history = history.append(y_test[next_pred.index])

y_pred_wfv.name = "prediction"
y_pred_wfv.index.name = "timestamp"
y_pred_wfv.head()

wqet_grader.grade("Project 3 Assessment", "Task 3.5.16", y_pred_wfv)

"""**Task 3.5.17:** Submit your walk-forward validation predictions to the grader to see the test mean absolute error for your model."""

wqet_grader.grade("Project 3 Assessment", "Task 3.5.17", y_pred_wfv)

"""## **Communicate Results**

**Task 3.5.18:** Put the values for y_test and y_pred_wfv into the DataFrame df_pred_test (don't forget the index). Then plot df_pred_test using plotly express. In the legend, your lines should be labeled "y_test" and "y_pred_wfv". Be sure to label the x-axis as "Date" and the y-axis as "PM2.5 Level". Use the title "Dar es Salaam, WFV Predictions".
"""

df_pred_test = pd.DataFrame(
    {
        "y_test": y_test, "y_pred_wfv": y_pred_wfv
    }
)
fig = px.line(df_pred_test, labels={"value": "PM2.5"})
fig.update_layout(
    title="Dar es Salaam, WFV Predictions",
    xaxis_title="Date",
    yaxis_title="PM2.5 Level",
)
# Don't delete the code below ðŸ‘‡
fig.write_image("images/3-5-18.png", scale=1, height=500, width=700)

fig.show()

with open("images/3-5-18.png", "rb") as file:
    wqet_grader.grade("Project 3 Assessment", "Task 3.5.18", file)

"""Copyright 2024 WorldQuant University. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited."""
